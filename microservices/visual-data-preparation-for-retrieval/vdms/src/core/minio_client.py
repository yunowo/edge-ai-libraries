# Copyright (C) 2025 Intel Corporation
# SPDX-License-Identifier: Apache-2.0

import io
import os
import pathlib
from http import HTTPStatus
from typing import List, Optional, Tuple

from minio import Minio
from minio.error import S3Error

from src.common import DataPrepException, Strings
from src.logger import logger


class MinioClient:
    """Singleton class for Minio Client operations.
    Provides methods to interact with Minio object storage.
    """

    _instance = None

    def __new__(cls, *args, **kwargs):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
            cls._instance.client = None
        return cls._instance

    def __init__(self, endpoint: str, access_key: str, secret_key: str, secure: bool = False):
        """Initialize Minio client if not already initialized.

        Args:
            endpoint (str): Minio server endpoint (host:port)
            access_key (str): Minio access key
            secret_key (str): Minio secret key
            secure (bool, optional): Whether to use HTTPS. Defaults to False.
        """
        if not self.client:
            try:
                self.client = Minio(
                    endpoint, access_key=access_key, secret_key=secret_key, secure=secure
                )
                logger.info(f"Minio client initialized with endpoint: {endpoint}")
            except Exception as ex:
                logger.error(f"Error initializing Minio client: {ex}")
                raise Exception(Strings.minio_conn_error)

    def ensure_bucket_exists(self, bucket_name: str):
        """Check if the specified bucket exists and raise an error if it doesn't.

        Args:
            bucket_name (str): The name of the bucket to check

        Raises:
            Exception: If bucket doesn't exist or check fails
        """
        try:
            if not self.client.bucket_exists(bucket_name):
                logger.error(f"Bucket '{bucket_name}' does not exist")
                raise DataPrepException(
                    status_code=HTTPStatus.NOT_FOUND, msg=f"Bucket '{bucket_name}' not found"
                )
            else:
                logger.debug(f"Bucket '{bucket_name}' exists")
        except S3Error as ex:
            logger.error(f"Error checking if bucket exists: {ex}")
            raise Exception(f"Error while checking whether bucket {bucket_name} exists.")

    def list_videos(self, bucket_name: str, prefix: str = "") -> List[str]:
        """List all video files in the specified bucket with the given prefix.

        Args:
            bucket_name (str): The bucket to search in
            prefix (str, optional): Directory prefix to search in. Defaults to "".

        Returns:
            List[str]: List of video filenames

        Raises:
            Exception: If listing objects fails
        """
        try:
            # Ensure prefix ends with a "/" if not empty
            if prefix and not prefix.endswith("/"):
                prefix += "/"

            # List all objects in the bucket with the given prefix
            objects = self.client.list_objects(bucket_name, prefix=prefix, recursive=True)

            # Filter for .mp4 files only
            video_files = []
            for obj in objects:
                if obj.object_name.lower().endswith(".mp4"):
                    # Return only the filename part without the prefix
                    path = pathlib.Path(obj.object_name)
                    video_files.append(path.name)

            return video_files
        except S3Error as ex:
            logger.error(f"Error listing objects in bucket {bucket_name}: {ex}")
            raise Exception(f"Error listing videos in bucket {bucket_name}: {ex}")

    def list_video_directories(self, bucket_name: str) -> List[Tuple[str, List[str]]]:
        """List all directories in the bucket and find video files in each.
        Each directory is treated as a video_id folder.

        Args:
            bucket_name (str): The bucket to search in

        Returns:
            List[Tuple[str, List[str]]]: List of tuples (video_id, list of video files in that directory)

        Raises:
            Exception: If listing objects fails
        """
        try:
            # First get all objects to identify directories
            all_objects = list(self.client.list_objects(bucket_name, recursive=True))

            # Extract unique directories (video_ids)
            directories = set()
            for obj in all_objects:
                path = pathlib.Path(obj.object_name)
                if len(path.parts) > 1:  # Has at least one directory component
                    directories.add(path.parts[0])

            # For each directory, find videos
            result = []
            for directory in directories:
                videos = []
                for obj in all_objects:
                    if obj.object_name.startswith(
                        f"{directory}/"
                    ) and obj.object_name.lower().endswith(".mp4"):
                        videos.append(pathlib.Path(obj.object_name).name)

                if videos:  # Only include directories that have videos
                    result.append((directory, videos))

            return result
        except S3Error as ex:
            logger.error(f"Error listing directories in bucket {bucket_name}: {ex}")
            raise Exception(f"Error listing video directories in bucket {bucket_name}: {ex}")

    def get_video_in_directory(self, bucket_name: str, video_id: str) -> Optional[str]:
        """Get the first video file found in the specified directory.

        Args:
            bucket_name (str): The bucket to search in
            video_id (str): The directory (video_id) to search in

        Returns:
            Optional[str]: Full object name of the first video found, or None if no videos found

        Raises:
            Exception: If listing objects fails
        """
        try:
            # Ensure video_id ends with "/"
            prefix = f"{video_id}/" if not video_id.endswith("/") else video_id

            # List all objects in the directory
            objects = self.client.list_objects(bucket_name, prefix=prefix, recursive=True)

            # Find the first .mp4 file
            for obj in objects:
                if obj.object_name.lower().endswith(".mp4"):
                    return obj.object_name

            return None
        except S3Error as ex:
            logger.error(f"Error getting video in directory {video_id}: {ex}")
            raise Exception(f"Error getting video in directory {video_id}: {ex}")

    def download_video_stream(self, bucket_name: str, object_name: str) -> Optional[io.BytesIO]:
        """Download a video file as a stream.

        Args:
            bucket_name (str): The bucket containing the video
            object_name (str): The object name (path) of the video

        Returns:
            Optional[io.BytesIO]: BytesIO stream containing the video data

        Raises:
            Exception: If getting the object fails
        """
        try:
            response = self.client.get_object(bucket_name, object_name)
            data = io.BytesIO()
            for d in response.stream(32 * 1024):
                data.write(d)
            data.seek(0)
            response.close()
            response.release_conn()
            return data
        except S3Error as ex:
            logger.error(f"Error downloading video {object_name} from bucket {bucket_name}: {ex}")
            raise Exception(f"Error downloading video: {ex}")

    def get_object_size(self, bucket_name: str, object_name: str) -> int:
        """Get the size of an object in bytes.

        Args:
            bucket_name (str): The bucket containing the object
            object_name (str): The object name

        Returns:
            int: Size of the object in bytes

        Raises:
            Exception: If getting the object stats fails
        """
        try:
            obj_stat = self.client.stat_object(bucket_name, object_name)
            return obj_stat.size
        except S3Error as ex:
            logger.error(f"Error getting size of {object_name} from bucket {bucket_name}: {ex}")
            raise Exception(f"Error getting object size: {ex}")

    def list_all_videos(self, bucket_name: str) -> List[dict]:
        """List all videos in the bucket with one video per video_id directory.

        Args:
            bucket_name (str): The bucket to search in

        Returns:
            List[dict]: List of dictionaries with video information including video_id, video_name,
                        video_path and creation_ts

        Raises:
            Exception: If listing objects fails
        """
        try:
            # Get all objects in the bucket
            all_objects = list(self.client.list_objects(bucket_name, recursive=True))

            # Find video files (expecting one video per directory)
            result = []
            for obj in all_objects:
                # Check if it's a video file (.mp4)
                if obj.object_name.lower().endswith(".mp4"):
                    # Parse the path to get video_id and video_name
                    path = pathlib.Path(obj.object_name)

                    # Only process if the path has a directory structure (video_id/filename)
                    if len(path.parts) > 1:
                        video_id = path.parts[0]
                        video_name = path.name

                        # Get metadata including creation timestamp
                        metadata = self.get_object_metadata(bucket_name, obj.object_name)

                        video_info = {
                            "video_id": video_id,
                            "video_name": video_name,
                            "video_path": obj.object_name,
                            "creation_ts": metadata["creation_time"],
                        }

                        result.append(video_info)

            return result

        except S3Error as ex:
            logger.error(f"Error listing videos in bucket {bucket_name}: {ex}")
            raise Exception(f"Error listing videos in bucket {bucket_name}: {ex}")

    def validate_object_name(self, video_id: str, video_name: str) -> bool:
        """Validate video_id and video_name based on Minio object naming rules.

        Args:
            video_id (str): The video ID (directory part)
            video_name (str): The video filename

        Returns:
            bool: True if valid, False otherwise
        """
        try:
            logger.debug(f"Validating object name: video_id={video_id}, video_name={video_name}")

            # Check for empty strings
            if not video_id or not video_name:
                return False

            # Check if video_name has a valid video extension (.mp4)
            if not video_name.lower().endswith(".mp4"):
                return False

            # Check for invalid characters in object names (basic check)
            invalid_chars = ["\\", "?", "#", "..", "/"]
            for char in invalid_chars:
                if char in video_id or char in video_name:
                    return False

            # Check total length (Minio has a 1024 character limit for object names)
            object_name = f"{video_id}/{video_name}"
            if len(object_name) > 1024:
                return False

            return True
        except Exception as ex:
            logger.error(f"Error validating object name: {ex}")
            return False

    def object_exists(self, bucket_name: str, video_id: str, video_name: str) -> bool:
        """Check if an object exists in the bucket.

        Args:
            bucket_name (str): The bucket to check in
            video_id (str): The video ID (directory part)
            video_name (str): The video filename

        Returns:
            bool: True if the object exists, False otherwise
        """
        try:
            object_name = f"{video_id}/{video_name}"
            self.client.stat_object(bucket_name, object_name)
            return True
        except S3Error:
            return False
        except Exception as ex:
            logger.error(f"Error checking if object exists: {ex}")
            return False

    def get_object_metadata(self, bucket_name: str, object_name: str) -> dict:
        """Get metadata information for an object, including creation timestamp.

        Args:
            bucket_name (str): The bucket containing the object
            object_name (str): The object name (path)

        Returns:
            dict: Dictionary with metadata information including creation timestamp

        Raises:
            Exception: If getting object stats fails
        """
        try:
            obj_stat = self.client.stat_object(bucket_name, object_name)
            return {
                "size": obj_stat.size,
                "creation_time": obj_stat.last_modified.isoformat(),
                "etag": obj_stat.etag,
                "content_type": obj_stat.content_type,
            }
        except S3Error as ex:
            logger.error(
                f"Error getting metadata for {object_name} from bucket {bucket_name}: {ex}"
            )
            raise Exception(f"Error getting object metadata: {ex}")

    def upload_video(self, bucket_name: str, object_name: str, data, file_size=None) -> None:
        """Upload a video file to Minio storage.

        Args:
            bucket_name (str): The bucket to upload to
            object_name (str): The object name including path (e.g., "video_id/filename.mp4")
            data: File-like object containing the video data
            file_size (int, optional): The size of the file in bytes. If not provided,
                                       it will be determined from the data object.

        Raises:
            Exception: If uploading the file fails or bucket doesn't exist
        """
        try:
            # Check if the bucket exists
            self.ensure_bucket_exists(bucket_name)

            # Upload the file
            self.client.put_object(
                bucket_name=bucket_name,
                object_name=object_name,
                data=data,
                length=file_size,
                content_type="video/mp4",
            )

            logger.info(f"Video uploaded successfully as {object_name} in bucket {bucket_name}")
        except S3Error as ex:
            logger.error(f"Error uploading video to Minio: {ex}")
            raise Exception(f"Error uploading video to Minio: {ex}")

    def save_metadata_file(
        self,
        bucket_name: str,
        metadata_content: bytes,
        video_id: str,
        filename: str = "metadata.json",
    ) -> str:
        """Save metadata file to minio.

        Args:
            bucket_name (str): The bucket to save to
            metadata_content (bytes): The content to save
            video_id (str): The directory (video_id) to save in
            filename (str, optional): The filename. Defaults to "metadata.json".

        Returns:
            str: The full object name of the saved file

        Raises:
            Exception: If putting the object fails or bucket doesn't exist
        """
        try:
            # Check if the bucket exists
            self.ensure_bucket_exists(bucket_name)

            # Prepare object name
            object_name = f"{video_id}/{filename}"

            # Create BytesIO object
            data = io.BytesIO(metadata_content)
            length = len(metadata_content)

            # Upload the file
            self.client.put_object(
                bucket_name=bucket_name,
                object_name=object_name,
                data=data,
                length=length,
                content_type="application/json",
            )

            logger.info(f"Metadata file saved as {object_name} in bucket {bucket_name}")
            return object_name
        except S3Error as ex:
            logger.error(f"Error saving metadata file: {ex}")
            raise Exception(f"Error saving metadata file: {ex}")
