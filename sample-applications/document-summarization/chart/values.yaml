# Default configuration values for the document summarization Helm chart
global:
  proxy:
    noProxy:
    httpProxy:
    httpsProxy:
  huggingface:
    token:
  ui:
    nodePort:
  otlp:
    otlpEndPoint:
  llm:
    llmModelId: "microsoft/Phi-3.5-mini-instruct"
    llmEndpointUrl: "http://ovms-service:8300"
  backendApi:
    url: "http://docsum-api:8090/v1/docsum"
  ovms:
    weightFormat: "int8"
    targetDevice: "CPU"
  ovms_pvc:
    size: 20Gi
  ovms_embed_pvc:
    size: 20Gi
  keeppvc: false # true  to persist models across multiple deployments

  docSum:
    name: document-summarization
    image:
      repository: "intel/document-summary"
      tag: "1.0.0"
      pullPolicy: IfNotPresent
nginx:
  image:
    repository: nginx
    tag: 1.27.1
    pullPolicy: IfNotPresent
docSumUI:
  name: docsum-ui
  service:
    type: ClusterIP
    port: 9998
    targetPort: 7860
  env:
    gradioPort: 7860

# Resource requests and limits
resources:
  limits:
    cpu: "1"
    memory: "1Gi"
  requests:
    cpu: "500m"
    memory: "512Mi"
