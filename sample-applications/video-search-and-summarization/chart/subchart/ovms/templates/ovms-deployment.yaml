apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ include "ovms.fullname" . }}
  labels:
    app: {{ include "ovms.name" . }}
spec:
  replicas: 1
  selector:
    matchLabels:
      app: {{ .Values.ovms.name }}
  template:
    metadata:
      labels:
        app: {{ .Values.ovms.name }}
    spec:
      initContainers:
        - name: init-script
          image: "python:3.10.12"
          command:
              - /bin/sh
              - -c
              - |
                if [ -f /opt/data/models/config.json ]; then
                  echo "Config file found, checking for model conversion."
                  if grep '"name": "{{ .Values.global.LLM_MODEL }}"' /opt/data/models/config.json; then
                    echo "Model already converted, skipping conversion."
                  else
                    echo "Model not converted, running init script. /config/init-script.sh "{{ .Values.global.LLM_MODEL }}" "{{ .Values.ovms.env.WEIGHT_FORMAT }}" "{{ .Values.global.huggingface.apiToken }}""
                    . /config/init-script.sh
                  fi
                else
                  echo "No config.json found, running init script. /config/init-script.sh "{{ .Values.global.LLM_MODEL }}" "{{ .Values.ovms.env.WEIGHT_FORMAT }}" "{{ .Values.global.huggingface.apiToken }}""
                  . /config/init-script.sh
                fi
          args: ["{{ .Values.global.LLM_MODEL}}","{{ .Values.ovms.env.WEIGHT_FORMAT }}","{{ .Values.global.huggingface.apiToken }}"]
          env:
            - name: http_proxy
              value: {{ .Values.global.proxy.http_proxy }}
            - name: https_proxy
              value: {{ .Values.global.proxy.https_proxy }}
            - name: no_proxy
              value: "{{ .Values.global.proxy.no_proxy }},localhost,127.0.0.1,audiointelligence,vlm-inference-microservice,videosummarybackend,videoingestion,minio-server,postgresql,video-summary-nginx,rabbitmq,multimodal-embedding-ms,vdms-dataprep,vdms-vectordb,videosearch,.svc.cluster.local"
          volumeMounts:
            - name: scripts-volume
              mountPath: /config
            - name: workspace
              mountPath: /opt/data
      containers:
        - name: {{ .Values.ovms.name }}
          image: {{ .Values.ovms.image.repository }}:{{ .Values.ovms.image.tag }}
          imagePullPolicy: {{ .Values.ovms.image.pullPolicy }}
          readinessProbe:
            httpGet:
              path: {{ .Values.ovms.readinessProbe.httpGet.path }}
              port: {{ .Values.ovms.readinessProbe.httpGet.port }}
            initialDelaySeconds: {{ .Values.ovms.readinessProbe.initialDelaySeconds }}
            periodSeconds: {{ .Values.ovms.readinessProbe.periodSeconds }}
          ports:
            - containerPort: {{ .Values.ovms.service.port }}
          volumeMounts:
            - name: scripts-volume
              mountPath: /config
            - name: workspace
              mountPath: /opt/data
          env:
            - name: http_proxy
              value: {{ .Values.global.proxy.http_proxy }}
            - name: https_proxy
              value: {{ .Values.global.proxy.https_proxy }}
            - name: no_proxy
              value: "{{ .Values.global.proxy.no_proxy }},localhost,127.0.0.1,audiointelligence,vlm-inference-microservice,videosummarybackend,videoingestion,minio-server,postgresql,video-summary-nginx,rabbitmq,multimodal-embedding-ms,vdms-dataprep,vdms-vectordb,videosearch,.svc.cluster.local"
            - name: WEIGHT_FORMAT
              value: {{ .Values.ovms.env.WEIGHT_FORMAT }}
          args: ["--port", "9300", "--rest_port", "8300", "--log_level", "DEBUG", "--config_path", "/opt/data/models/config.json"]
      volumes:
        - name: workspace
          persistentVolumeClaim:
            claimName: video-summary-ovms-pvc
        - name: scripts-volume
          configMap:
            name: {{ .Values.ovms.script.name }}
            defaultMode: 0777
